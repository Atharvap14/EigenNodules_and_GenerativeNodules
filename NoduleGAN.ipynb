{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "# Define a custom dataset\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class TotalVariationLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TotalVariationLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h_x = x.size(2)\n",
    "        w_x = x.size(3)\n",
    "        count_h = self.tensor_size(x[:,:,1:,:])\n",
    "        count_w = self.tensor_size(x[:,:,:,1:])\n",
    "        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n",
    "        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n",
    "        return 2*(h_tv/count_h+w_tv/count_w)/batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.size(1)*t.size(2)*t.size(3)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path,transform=None):\n",
    "        self.transform = transform\n",
    "        self.data=os.listdir(path)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # TODO: return one item on the index\n",
    "        x = cv2.imread(f'patches/{self.data[index]}')\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO: return the data length\n",
    "        return len(self.data)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.GaussianBlur(3),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = CustomDataset(\"patches\",transform=transform)\n",
    "# Initialize the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, img_dim=64*64):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "# Define the discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=64*64):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.001\n",
    "z_dim = 64\n",
    "img_dim = 64*64\n",
    "batch_size = 32\n",
    "num_epochs = 1000\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "gen = Generator(z_dim, img_dim)\n",
    "disc = Discriminator(img_dim)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "tv=TotalVariationLoss()\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for batch_idx, (real) in enumerate(dataloader):\n",
    "        real = real.view(-1, 4096)\n",
    "        batch_size = real.shape[0]\n",
    "        noise = torch.randn(batch_size, z_dim)\n",
    "        fake = gen(noise)\n",
    "        if(epoch%7==0):\n",
    "            # Train Discriminator\n",
    "            disc_real = disc(real).view(-1)\n",
    "            lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "            disc_fake = disc(fake).view(-1)\n",
    "            lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "            lossD = (lossD_real + lossD_fake) / 2\n",
    "            disc.zero_grad()\n",
    "            lossD.backward(retain_graph=True)\n",
    "            opt_disc.step()\n",
    "\n",
    "        # Train Generator\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))+tv(fake.reshape(-1,1,64,64))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx==0 and epoch%10==0:\n",
    "            print(\"Epoch: \",epoch,\"| GenLoss: \",lossG.item(),\"| DiscLoss: \",lossD.item())\n",
    "            with torch.no_grad():\n",
    "                fake = gen(torch.randn(batch_size, z_dim)).reshape(-1,1,64,64)\n",
    "                real_np=real.reshape(-1,1,64,64)[0][0].cpu().numpy()\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                print(img_grid_fake.shape)\n",
    "\n",
    "                img_np = fake[0][0].cpu().numpy()\n",
    "                plt.imshow(img_np,cmap='Greys')\n",
    "                plt.show()\n",
    "                plt.imshow(real_np,cmap='Greys')\n",
    "                plt.show()\n",
    "\n",
    "                # plt.waitforbuttonpress()\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "# Define a custom dataset\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class TotalVariationLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TotalVariationLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h_x = x.size(2)\n",
    "        w_x = x.size(3)\n",
    "        count_h = self.tensor_size(x[:,:,1:,:])\n",
    "        count_w = self.tensor_size(x[:,:,:,1:])\n",
    "        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n",
    "        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n",
    "        return 2*(h_tv/count_h+w_tv/count_w)/batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.size(1)*t.size(2)*t.size(3)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path,transform=None):\n",
    "        self.transform = transform\n",
    "        self.data=os.listdir(path)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # TODO: return one item on the index\n",
    "        x = cv2.imread(f'patches/{self.data[index]}')\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO: return the data length\n",
    "        return len(self.data)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.GaussianBlur(3),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = CustomDataset(\"patches\",transform=transform)\n",
    "# Initialize the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, img_dim=64*64):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "# Define the discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=64*64):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.001\n",
    "z_dim = 64\n",
    "img_dim = 64*64\n",
    "batch_size = 32\n",
    "num_epochs = 300\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "gen = Generator(z_dim, img_dim)\n",
    "disc = Discriminator(img_dim)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "tv=TotalVariationLoss()\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for batch_idx, (real) in enumerate(dataloader):\n",
    "        real = real.view(-1, 4096)\n",
    "        batch_size = real.shape[0]\n",
    "        noise = torch.randn(batch_size, z_dim)\n",
    "        fake = gen(noise)\n",
    "        if(epoch%7==0):\n",
    "            # Train Discriminator\n",
    "            disc_real = disc(real).view(-1)\n",
    "            lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "            disc_fake = disc(fake).view(-1)\n",
    "            lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "            lossD = (lossD_real + lossD_fake) / 2\n",
    "            disc.zero_grad()\n",
    "            lossD.backward(retain_graph=True)\n",
    "            opt_disc.step()\n",
    "\n",
    "        # Train Generator\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))+0.1*tv(fake.reshape(-1,1,64,64))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx==0 and epoch%10==0:\n",
    "            print(\"Epoch: \",epoch,\"| GenLoss: \",lossG.item(),\"| DiscLoss: \",lossD.item())\n",
    "            with torch.no_grad():\n",
    "                fake = gen(torch.randn(batch_size, z_dim)).reshape(-1,1,64,64)\n",
    "                real_np=real.reshape(-1,1,64,64)[0][0].cpu().numpy()\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                print(img_grid_fake.shape)\n",
    "\n",
    "                img_np = fake[0][0].cpu().numpy()\n",
    "                plt.imshow(img_np,cmap='Greys')\n",
    "                plt.show()\n",
    "                plt.imshow(real_np,cmap='Greys')\n",
    "                plt.show()\n",
    "\n",
    "                # plt.waitforbuttonpress()\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "# Define a custom dataset\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class TotalVariationLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TotalVariationLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h_x = x.size(2)\n",
    "        w_x = x.size(3)\n",
    "        count_h = self.tensor_size(x[:,:,1:,:])\n",
    "        count_w = self.tensor_size(x[:,:,:,1:])\n",
    "        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n",
    "        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n",
    "        return 2*(h_tv/count_h+w_tv/count_w)/batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.size(1)*t.size(2)*t.size(3)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path,transform=None):\n",
    "        self.transform = transform\n",
    "        self.data=os.listdir(path)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # TODO: return one item on the index\n",
    "        x = cv2.imread(f'patches/{self.data[index]}')\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO: return the data length\n",
    "        return len(self.data)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.GaussianBlur(3),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = CustomDataset(\"patches\",transform=transform)\n",
    "# Initialize the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,z_dim, img_dim):\n",
    "        super(Generator,self).__init__()\n",
    "        self.tconv1 = nn.ConvTranspose2d(z_dim,1024,kernel_size = 4,stride = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(1024);\n",
    "\n",
    "        self.tconv2 = nn.ConvTranspose2d(1024,512,kernel_size = 4,stride = 2,padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(512);\n",
    "\n",
    "        self.tconv3 = nn.ConvTranspose2d(512,256,kernel_size = 4,stride = 2,padding = 1)\n",
    "        self.bn3 = nn.BatchNorm2d(256);\n",
    "\n",
    "        self.tconv3_a = nn.ConvTranspose2d(256,128,kernel_size = 4,stride = 2,padding = 1)\n",
    "        self.bn3_a = nn.BatchNorm2d(128);\n",
    "\n",
    "        self.tconv4 = nn.ConvTranspose2d(128,1,kernel_size = 4,stride = 2,padding = 1)\n",
    "        self._init_weights()\n",
    "    def forward(self,x): #(100,1,1)\n",
    "        # print(x.shape)\n",
    "        x = F.leaky_relu(self.bn1(self.tconv1(x)), negative_slope=0.02, inplace=False)# (B,1024,4,4)\n",
    "        # print(x.shape)\n",
    "        x = F.leaky_relu(self.bn2(self.tconv2(x)), negative_slope=0.02, inplace=False)# (B,512,8,8)\n",
    "        # print(x.shape)\n",
    "        x = F.leaky_relu(self.bn3(self.tconv3(x)), negative_slope=0.02, inplace=False)# (B,256,16,16)\n",
    "        # print(x.shape)\n",
    "        x = F.leaky_relu(self.bn3_a(self.tconv3_a(x)), negative_slope=0.02, inplace=False)# (B,256,16,16)\n",
    "        # print(x.shape)\n",
    "        x = F.tanh((self.tconv4(x))) # (B,1,256,256)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,(nn.ConvTranspose2d)):\n",
    "                nn.init.normal_(m.weight.data,0,0.02)\n",
    "            if isinstance(m,(nn.BatchNorm2d)):\n",
    "                nn.init.normal_(m.weight.data,1.0,0.02)\n",
    "                nn.init.constant_(m.bias.data,0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=64*64):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.001\n",
    "z_dim = 64\n",
    "img_dim = 64*64\n",
    "batch_size = 32\n",
    "num_epochs = 300\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "gen = Generator(z_dim, img_dim)\n",
    "disc = Discriminator(img_dim)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "tv=TotalVariationLoss()\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for batch_idx, (real) in enumerate(dataloader):\n",
    "        real = real.view(-1, 4096)\n",
    "        batch_size = real.shape[0]\n",
    "        noise = torch.randn(batch_size, z_dim,1,1)\n",
    "        \n",
    "        fake = gen(noise)\n",
    "        if(epoch%7==0):\n",
    "            # Train Discriminator\n",
    "            disc_real = disc(real).view(-1)\n",
    "            lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "            disc_fake = disc(fake.reshape(-1,4096)).view(-1)\n",
    "            lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "            lossD = (lossD_real + lossD_fake) / 2\n",
    "            disc.zero_grad()\n",
    "            lossD.backward(retain_graph=True)\n",
    "            opt_disc.step()\n",
    "\n",
    "        # Train Generator\n",
    "        output = disc(fake.reshape(-1,4096)).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))+tv(fake.reshape(-1,1,64,64))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx==0 and epoch%10==0:\n",
    "            print(\"Epoch: \",epoch,\"| GenLoss: \",lossG.item(),\"| DiscLoss: \",lossD.item())\n",
    "            with torch.no_grad():\n",
    "                fake = gen(torch.randn(batch_size, z_dim,1,1)).reshape(-1,1,64,64)\n",
    "                real_np=real.reshape(-1,1,64,64)[0][0].cpu().numpy()\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                # print(img_grid_fake.shape)\n",
    "\n",
    "                img_np = fake[0][0].cpu().numpy()\n",
    "                plt.imshow(img_np,cmap='Greys')\n",
    "                plt.show()\n",
    "                plt.imshow(real_np,cmap='Greys')\n",
    "                plt.show()\n",
    "\n",
    "                # plt.waitforbuttonpress()\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "# Define a custom dataset\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class TotalVariationLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TotalVariationLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h_x = x.size(2)\n",
    "        w_x = x.size(3)\n",
    "        count_h = self.tensor_size(x[:,:,1:,:])\n",
    "        count_w = self.tensor_size(x[:,:,:,1:])\n",
    "        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n",
    "        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n",
    "        return 2*(h_tv/count_h+w_tv/count_w)/batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.size(1)*t.size(2)*t.size(3)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path,transform=None):\n",
    "        self.transform = transform\n",
    "        self.data=os.listdir(path)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # TODO: return one item on the index\n",
    "        x = cv2.imread(f'patches/{self.data[index]}')\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO: return the data length\n",
    "        return len(self.data)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.GaussianBlur(3),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = CustomDataset(\"patches\",transform=transform)\n",
    "# Initialize the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, channels_img=1, features_g=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            # Input: N x z_dim x 1 x 1\n",
    "            self._block1(z_dim, features_g * 16, 3, 1, 1),  # img: 4x4\n",
    "            self._block(features_g * 16, features_g * 8, 3, 1, 1),  # img: 8x8\n",
    "            self._block(features_g * 8, features_g * 4, 3, 1, 1),  # img: 16x16\n",
    "            self._block(features_g * 4, features_g * 2, 3, 1, 1),  # img: 32x32\n",
    "             # Output: N x channels_img x 64 x 64\n",
    "            \n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(\n",
    "                 features_g * 2, channels_img, 3, 1, 1, bias=False,\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n",
    "            ),\n",
    "            \n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def _block1(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=4, mode='bilinear'),\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n",
    "            ),\n",
    "            \n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=64*64):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.001\n",
    "z_dim = 64\n",
    "img_dim = 64*64\n",
    "batch_size = 32\n",
    "num_epochs = 300\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize generator and discriminator\n",
    "gen = Generator(z_dim).to(device)\n",
    "disc = Discriminator(img_dim).to(device)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "tv=TotalVariationLoss()\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for batch_idx, (real) in enumerate(dataloader):\n",
    "        real = real.view(-1, 4096).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "        noise = torch.randn(batch_size, z_dim,1,1).to(device)\n",
    "        \n",
    "        fake = gen(noise)\n",
    "        if(epoch%7==0):\n",
    "            # Train Discriminator\n",
    "            disc_real = disc(real).view(-1)\n",
    "            lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "            disc_fake = disc(fake.reshape(-1,4096)).view(-1)\n",
    "            lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "            lossD = (lossD_real + lossD_fake) / 2\n",
    "            disc.zero_grad()\n",
    "            lossD.backward(retain_graph=True)\n",
    "            opt_disc.step()\n",
    "\n",
    "        # Train Generator\n",
    "        output = disc(fake.reshape(-1,4096)).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))#+tv(fake.reshape(-1,1,64,64))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx==0 and epoch%10==0:\n",
    "            print(\"Epoch: \",epoch,\"| GenLoss: \",lossG.item(),\"| DiscLoss: \",lossD.item())\n",
    "            with torch.no_grad():\n",
    "                fake = gen(torch.randn(batch_size, z_dim,1,1).to(device)).reshape(-1,1,64,64)\n",
    "                real_np=real.reshape(-1,1,64,64)[0][0].cpu().numpy()\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                # print(img_grid_fake.shape)\n",
    "\n",
    "                img_np = fake[0][0].cpu().numpy()\n",
    "                plt.imshow(img_np,cmap='Greys')\n",
    "                plt.show()\n",
    "                plt.imshow(real_np,cmap='Greys')\n",
    "                plt.show()\n",
    "\n",
    "                # plt.waitforbuttonpress()\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), \"NoduleGenerator.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "# Define a custom dataset\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class TotalVariationLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TotalVariationLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h_x = x.size(2)\n",
    "        w_x = x.size(3)\n",
    "        count_h = self.tensor_size(x[:,:,1:,:])\n",
    "        count_w = self.tensor_size(x[:,:,:,1:])\n",
    "        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n",
    "        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n",
    "        return 2*(h_tv/count_h+w_tv/count_w)/batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.size(1)*t.size(2)*t.size(3)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path,transform=None):\n",
    "        self.transform = transform\n",
    "        self.data=os.listdir(path)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # TODO: return one item on the index\n",
    "        x = cv2.imread(f'patches/{self.data[index]}')\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO: return the data length\n",
    "        return len(self.data)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.GaussianBlur(3),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = CustomDataset(\"patches\",transform=transform)\n",
    "# Initialize the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class GeneratorA(nn.Module):\n",
    "    def __init__(self, z_dim=10, channels_img=1, features_g=64):\n",
    "        super(GeneratorA, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            # Input: N x z_dim x 1 x 1\n",
    "            self._block1(z_dim, features_g * 16, 3, 1, 1),  # img: 4x4\n",
    "            self._block(features_g * 16, features_g * 8, 3, 1, 1),  # img: 8x8\n",
    "            self._block(features_g * 8, features_g * 4, 3, 1, 1),  # img: 16x16\n",
    "            self._block(features_g * 4, features_g * 2, 3, 1, 1),  # img: 32x32\n",
    "             # Output: N x channels_img x 64 x 64\n",
    "            \n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(\n",
    "                 features_g * 2, channels_img, 3, 1, 1, bias=False,\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n",
    "            ),\n",
    "            \n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def _block1(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=4, mode='bilinear'),\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n",
    "            ),\n",
    "            \n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "\n",
    "\n",
    "# Define the generator\n",
    "class GeneratorB(nn.Module):\n",
    "    def __init__(self, z_dim=10, img_dim=64*64):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "\n",
    "\n",
    "# Define the discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=64*64):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.001\n",
    "z_dim = 64\n",
    "img_dim = 64*64\n",
    "batch_size = 32\n",
    "num_epochs = 300\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize generator and discriminator\n",
    "genA = GeneratorA(z_dim).to(device)\n",
    "genB= GeneratorB(z_dim).to(device)\n",
    "disc = Discriminator(img_dim).to(device)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "tv=TotalVariationLoss()\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "alpha=0.08\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for batch_idx, (real) in enumerate(dataloader):\n",
    "        real = real.view(-1, 4096).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "        noise = torch.randn(batch_size, z_dim,1,1).to(device)\n",
    "        \n",
    "        fake = genA(noise)+alpha*genB(noise.reshape(-1,z_dim)).reshape(-1,64,64)\n",
    "        if(epoch%7==0):\n",
    "            # Train Discriminator\n",
    "            disc_real = disc(real).view(-1)\n",
    "            lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "            disc_fake = disc(fake.reshape(-1,4096)).view(-1)\n",
    "            lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "            lossD = (lossD_real + lossD_fake) / 2\n",
    "            disc.zero_grad()\n",
    "            lossD.backward(retain_graph=True)\n",
    "            opt_disc.step()\n",
    "\n",
    "        # Train Generator\n",
    "        output = disc(fake.reshape(-1,4096)).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))+tv(fake)\n",
    "        genA.zero_grad()\n",
    "        genB.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx==0 and epoch%10==0:\n",
    "            print(\"Epoch: \",epoch,\"| GenLoss: \",lossG.item(),\"| DiscLoss: \",lossD.item())\n",
    "            with torch.no_grad():\n",
    "                noise=torch.randn(batch_size, z_dim,1,1).to(device)\n",
    "                fake = genA(noise).reshape(-1,1,64,64)+alpha*genB(noise.reshape(-1,64)).reshape(-1,64,64)\n",
    "                real_np=real.reshape(-1,1,64,64)[0][0].cpu().numpy()\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                # print(img_grid_fake.shape)\n",
    "\n",
    "                img_np = fake[0][0].cpu().numpy()\n",
    "                plt.imshow(img_np,cmap='Greys')\n",
    "                plt.show()\n",
    "                plt.imshow(real_np,cmap='Greys')\n",
    "                plt.show()\n",
    "\n",
    "                # plt.waitforbuttonpress()\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(genA.state_dict(), \"NoduleGeneratorA.pt\")\n",
    "torch.save(genB.state_dict(), \"NoduleGeneratorB.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
